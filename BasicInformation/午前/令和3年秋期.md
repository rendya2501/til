# 令和3年秋期

01 エ×→イ

128
1000 0000
8 0

16 ^-1 8 * 16^-2

8 / 16^-2 = 1 / 2 * 16 = 1 / 32

1/128 * 16 = 1/8
1/8 * 16 = 2

16^-2 * 2 = 1 / 128

---

02 ア×→イ

32-28 = 4

1111 = 8倍×
2^4 = 16倍○

2^32 / 2^28 = 2^32-28 = 2^4 = 16

---

03

カルノー図の奴。
やったことはあるがどうやったか忘れてしまった。

A_B_C_D_ * A_B_C_D

---

04 エ○

---

05 ウ○

0 → 100:A → 300:K → 200:T → 0
0 → 100:A → G → 300:k → 200:T → 0
Aの次→a
Gの前、次 → x,y
kの前→f

---

06 ウ ○

受理される状態はなんだったか。
あ、a~dの各場合において110を入れて最終的にどこに行くか調べればいいだけかな。

---

07 ア ○

ディープラーニングの定義は何か。  
人間の脳神経回路を模すものだったっけ？  
ここらへんの説明色々ありすぎて毎回わからなくなる。  
ラーニングというからには学習であり、大量のデータは必要。
でもそれだけだと機械学習にもなりかねない。
機械学習が大量のデータの中から特徴点を抽出するだけの仕組みなら、ニューラルネットワークを組み合わせて、多数の推論をするのがディープっぽい雰囲気もするけどどうだっけかね。

一番迷ったイはデータマイニングだって。
統計的手法を用いて隠れた相関等を見つけるのがデータマイニングに当たるそうな。  

---

08 ア×→エ

再帰。
f 4,2
= f 3,1(f2,0(1※) + f2,1(f1,0(1※) + f1,1(1※))) + f 3,2(f2,1(f1,0(1※) + f1,1(1※)) + f2,2(1※))
= 6

f 3,1 = f 2,0 + f 2,1

f2,0 = 1
f2,1 = f1,0 + f1,1

f1,0 = 1
f1,1 = 1

②
f 3,2 = f 2,1 ⑤ + f 2,2 ⑥
⑤f2,1 = f 1,0 = 1
⑥f2,2 = f 1

おいおいって感じではある。  
再帰の計算って地道に左から順に解いていくのがいいのかもね。
変に分けたりすると追うのが大変になる。

---

09 ア ○

イではない。  
非常に大きい数の指数はあっという間に大きくなってしまうから近似どころではない。
+1が無視できる程度であることを考えれば、非常に小さくないとやってられない気がするけど？

大体合ってた。
応用の時の解説でも、実際に値を入れて「まぁ近似できるでしょうって感じで解説してるしね。」

---

10 イ ○

adb
c

---

11 イ ○

x=6 , y=4

6<4
r = 6-4 = 2
q = 1

2 < 4
x/y qは商
rが余り

x/y = x÷y

1/2 は 1÷2 2分の1

割り算がわからなくなった。
ゲシュタルト崩壊下。

---

12 ウ ○

2000 * 1600 = 3200 * 10^3 = 3.2 * 10^6

---

13 ウ○

パイプラインもまとめたいなーって思ってたところです。  

---

14 ア○

今日やったから覚えてる。  
てか、この問題平成23年からの焼き増しなのか。  


応用の情報も平気で出るから疲れる。  
そうだ。
まぁ、午前の問題を進めるのもいいけど、まとめたいと思っていた奴をまとめることにしたらすっきりするんじゃないかなー。

